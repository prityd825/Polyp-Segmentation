{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "875da784",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-30T05:43:47.721670Z",
     "iopub.status.busy": "2024-10-30T05:43:47.720962Z",
     "iopub.status.idle": "2024-10-30T05:43:55.197308Z",
     "shell.execute_reply": "2024-10-30T05:43:55.196537Z"
    },
    "papermill": {
     "duration": 7.485826,
     "end_time": "2024-10-30T05:43:55.199702",
     "exception": false,
     "start_time": "2024-10-30T05:43:47.713876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.20 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "from torchvision import models  \n",
    "from tqdm import tqdm\n",
    "from torchvision.models import vit_b_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "824b0bf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T05:43:55.212379Z",
     "iopub.status.busy": "2024-10-30T05:43:55.211967Z",
     "iopub.status.idle": "2024-10-30T05:43:55.223348Z",
     "shell.execute_reply": "2024-10-30T05:43:55.222525Z"
    },
    "papermill": {
     "duration": 0.0197,
     "end_time": "2024-10-30T05:43:55.225277",
     "exception": false,
     "start_time": "2024-10-30T05:43:55.205577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def augment_data(images, masks, save_path, augment=True):\n",
    "    size = (224, 224)  # Resize all images and masks to this size\n",
    "\n",
    "    for idx, (x, y) in tqdm(enumerate(zip(images, masks)), total=len(images)):\n",
    "        \"\"\" Extracting the name from the image path \"\"\"\n",
    "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        \"\"\" Reading image and mask \"\"\"\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)  # Read image\n",
    "        y = imageio.mimread(y)[0]  # Read mask\n",
    "\n",
    "        if augment:\n",
    "            # Apply augmentations: Horizontal Flip, Vertical Flip, and Rotate\n",
    "            aug = HorizontalFlip(p=1.0)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x1 = augmented[\"image\"]\n",
    "            y1 = augmented[\"mask\"]\n",
    "\n",
    "            aug = VerticalFlip(p=1.0)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x2 = augmented[\"image\"]\n",
    "            y2 = augmented[\"mask\"]\n",
    "\n",
    "            aug = Rotate(limit=45, p=1.0)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x3 = augmented[\"image\"]\n",
    "            y3 = augmented[\"mask\"]\n",
    "\n",
    "            # List of original and augmented images and masks\n",
    "            X = [x, x1, x2, x3]\n",
    "            Y = [y, y1, y2, y3]\n",
    "        else:\n",
    "            # No augmentation, just save the original image and mask\n",
    "            X = [x]\n",
    "            Y = [y]\n",
    "\n",
    "        # Save images and masks\n",
    "        index = 0\n",
    "        for i, m in zip(X, Y):\n",
    "            # Resize images and masks\n",
    "            i = cv2.resize(i, size)\n",
    "            m = cv2.resize(m, size)\n",
    "\n",
    "            # Create filenames for the augmented data\n",
    "            tmp_image_name = f\"{name}_{index}.png\"\n",
    "            tmp_mask_name = f\"{name}_{index}.png\"\n",
    "\n",
    "            # Create paths to save images and masks\n",
    "            image_path = os.path.join(save_path, \"image\", tmp_image_name)\n",
    "            mask_path = os.path.join(save_path, \"mask\", tmp_mask_name)\n",
    "\n",
    "            # Save images and masks to the directory\n",
    "            cv2.imwrite(image_path, i)\n",
    "            cv2.imwrite(mask_path, m)\n",
    "\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f0f04d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T05:43:55.238333Z",
     "iopub.status.busy": "2024-10-30T05:43:55.238044Z",
     "iopub.status.idle": "2024-10-30T05:43:55.244614Z",
     "shell.execute_reply": "2024-10-30T05:43:55.243852Z"
    },
    "papermill": {
     "duration": 0.015724,
     "end_time": "2024-10-30T05:43:55.246391",
     "exception": false,
     "start_time": "2024-10-30T05:43:55.230667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding for reproducibility \"\"\"\n",
    "    np.random.seed(42)\n",
    "\n",
    "    \"\"\" Directories for images and masks \"\"\"\n",
    "    image_dir = \"/kaggle/input/multi-center-polypbd/PolypDB/PolypDB_modality_wise/WLI/images\"\n",
    "    mask_dir = \"/kaggle/input/multi-center-polypbd/PolypDB/PolypDB_modality_wise/WLI/masks\"\n",
    "    save_path_train = \"/kaggle/working/augmented_data/train\"\n",
    "    save_path_test = \"/kaggle/working/augmented_data/test\"\n",
    "\n",
    "    os.makedirs(os.path.join(save_path_train, \"image\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_path_train, \"mask\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_path_test, \"image\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_path_test, \"mask\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e85f69a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T05:43:55.259057Z",
     "iopub.status.busy": "2024-10-30T05:43:55.258772Z",
     "iopub.status.idle": "2024-10-30T05:43:56.452476Z",
     "shell.execute_reply": "2024-10-30T05:43:56.451520Z"
    },
    "papermill": {
     "duration": 1.203131,
     "end_time": "2024-10-30T05:43:56.454782",
     "exception": false,
     "start_time": "2024-10-30T05:43:55.251651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_paths = sorted([os.path.join(image_dir, img) for img in os.listdir(image_dir) if img.endswith('.jpg') or img.endswith('.png')])\n",
    "mask_paths = sorted([os.path.join(mask_dir, mask) for mask in os.listdir(mask_dir) if mask.endswith('.jpg') or mask.endswith('.png')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a7b1d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T05:43:56.466759Z",
     "iopub.status.busy": "2024-10-30T05:43:56.466422Z",
     "iopub.status.idle": "2024-10-30T05:43:56.475790Z",
     "shell.execute_reply": "2024-10-30T05:43:56.475061Z"
    },
    "papermill": {
     "duration": 0.017387,
     "end_time": "2024-10-30T05:43:56.477683",
     "exception": false,
     "start_time": "2024-10-30T05:43:56.460296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c40c9bcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T05:43:56.489370Z",
     "iopub.status.busy": "2024-10-30T05:43:56.489079Z",
     "iopub.status.idle": "2024-10-30T05:47:29.265200Z",
     "shell.execute_reply": "2024-10-30T05:47:29.264248Z"
    },
    "papermill": {
     "duration": 212.785035,
     "end_time": "2024-10-30T05:47:29.267915",
     "exception": false,
     "start_time": "2024-10-30T05:43:56.482880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2870/2870 [03:04<00:00, 15.57it/s]\n",
      "100%|██████████| 718/718 [00:28<00:00, 25.28it/s]\n"
     ]
    }
   ],
   "source": [
    "augment_data(train_x, train_y, save_path_train, augment=True)\n",
    "augment_data(test_x, test_y, save_path_test, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a2fd45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T05:47:29.533816Z",
     "iopub.status.busy": "2024-10-30T05:47:29.532981Z",
     "iopub.status.idle": "2024-10-30T05:47:29.541414Z",
     "shell.execute_reply": "2024-10-30T05:47:29.540545Z"
    },
    "papermill": {
     "duration": 0.143359,
     "end_time": "2024-10-30T05:47:29.543216",
     "exception": false,
     "start_time": "2024-10-30T05:47:29.399857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PolypDB(Dataset):\n",
    "    def __init__(self, images_path, masks_path):\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.n_samples = len(images_path)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Reading image \"\"\"\n",
    "        image = cv2.imread(self.images_path[index], cv2.IMREAD_COLOR)\n",
    "        image = image / 255.0 \n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        image = image.astype(np.float32)\n",
    "        image = torch.from_numpy(image)\n",
    "        \n",
    "        \"\"\" Reading masks \"\"\"\n",
    "        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_GRAYSCALE)\n",
    "        mask = mask / 255.0 \n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "        mask = mask.astype(np.float32)\n",
    "        mask = torch.from_numpy(mask)\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76e604e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T05:47:29.849314Z",
     "iopub.status.busy": "2024-10-30T05:47:29.848476Z",
     "iopub.status.idle": "2024-10-30T05:47:29.868333Z",
     "shell.execute_reply": "2024-10-30T05:47:29.867483Z"
    },
    "papermill": {
     "duration": 0.194918,
     "end_time": "2024-10-30T05:47:29.870211",
     "exception": false,
     "start_time": "2024-10-30T05:47:29.675293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import vit_b_16\n",
    "\n",
    "# Example Encoder Block\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(encoder_block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip = self.conv(x)\n",
    "        pooled = self.pool(skip)\n",
    "        return skip, pooled\n",
    "\n",
    "# Example Decoder Block\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(decoder_block, self).__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.up(inputs)\n",
    "        # Resize x to match the size of skip for concatenation\n",
    "        x = F.interpolate(x, size=skip.size()[2:], mode='bilinear', align_corners=False)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "# Main UNet Model with ViT\n",
    "class build_unet_with_vit(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(build_unet_with_vit, self).__init__()\n",
    "\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        self.e1 = encoder_block(3, 64)\n",
    "        self.e2 = encoder_block(64, 128)\n",
    "        self.e3 = encoder_block(128, 256)\n",
    "        self.e4 = encoder_block(256, 512)\n",
    "\n",
    "        \"\"\" Conv layer to reduce channels from 512 to 3 for ViT \"\"\"\n",
    "        self.channel_reduction = nn.Conv2d(512, 3, kernel_size=1)\n",
    "\n",
    "        \"\"\" Vision Transformer as Bottleneck \"\"\"\n",
    "        self.vit_block = vit_b_16(pretrained=True)  # Load pre-trained ViT model\n",
    "\n",
    "        \"\"\" Fully Connected Layer to reshape ViT output \"\"\"\n",
    "        self.fc = nn.Linear(1000, 1024 * 7 * 7)  # Project ViT output to required shape\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block(1024, 512)\n",
    "        self.d2 = decoder_block(512, 256)\n",
    "        self.d3 = decoder_block(256, 128)\n",
    "        self.d4 = decoder_block(128, 64)\n",
    "\n",
    "        \"\"\" Classifier \"\"\"\n",
    "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        s1, p1 = self.e1(inputs)\n",
    "        s2, p2 = self.e2(p1)\n",
    "        s3, p3 = self.e3(p2)\n",
    "        s4, p4 = self.e4(p3)\n",
    "\n",
    "        \"\"\" Resize before Vision Transformer Bottleneck \"\"\"\n",
    "        p4_resized = F.interpolate(p4, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "\n",
    "        \"\"\" Reduce channels from 512 to 3 for ViT input \"\"\"\n",
    "        p4_reduced = self.channel_reduction(p4_resized)\n",
    "\n",
    "        \"\"\" Vision Transformer Block \"\"\"\n",
    "        vit_output = self.vit_block(p4_reduced)  # Output tensor of shape [batch_size, 1000]\n",
    "\n",
    "        \"\"\" Project and Reshape ViT output \"\"\"\n",
    "        vit_output_projected = self.fc(vit_output)  # Shape: [batch_size, 1024 * 7 * 7]\n",
    "        vit_output_reshaped = vit_output_projected.view(vit_output.size(0), 1024, 7, 7)  # Shape: [batch_size, 1024, 7, 7]\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.d1(vit_output_reshaped, s4)\n",
    "        d2 = self.d2(d1, s3)\n",
    "        d3 = self.d3(d2, s2)\n",
    "        d4 = self.d4(d3, s1)\n",
    "\n",
    "        outputs = self.outputs(d4)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a0b06f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T05:47:30.138137Z",
     "iopub.status.busy": "2024-10-30T05:47:30.137218Z",
     "iopub.status.idle": "2024-10-30T05:47:30.146763Z",
     "shell.execute_reply": "2024-10-30T05:47:30.145823Z"
    },
    "papermill": {
     "duration": 0.144956,
     "end_time": "2024-10-30T05:47:30.148625",
     "exception": false,
     "start_time": "2024-10-30T05:47:30.003669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = torch.sigmoid(inputs)  # Apply sigmoid activation\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return 1 - dice\n",
    "\n",
    "# Dice + Binary Cross-Entropy Loss\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_loss = 1 - (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
    "        bce = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        dice_bce = bce + dice_loss\n",
    "\n",
    "        return dice_bce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "608523db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T05:47:30.414603Z",
     "iopub.status.busy": "2024-10-30T05:47:30.413747Z",
     "iopub.status.idle": "2024-10-30T05:47:30.504313Z",
     "shell.execute_reply": "2024-10-30T05:47:30.503367Z"
    },
    "papermill": {
     "duration": 0.225872,
     "end_time": "2024-10-30T05:47:30.506695",
     "exception": false,
     "start_time": "2024-10-30T05:47:30.280823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = PolypDB(\n",
    "        images_path=sorted([os.path.join(save_path_train, \"image\", img) for img in os.listdir(os.path.join(save_path_train, \"image\"))]),\n",
    "        masks_path=sorted([os.path.join(save_path_train, \"mask\", mask) for mask in os.listdir(os.path.join(save_path_train, \"mask\"))])\n",
    "    )\n",
    "test_dataset = PolypDB(\n",
    "        images_path=sorted([os.path.join(save_path_test, \"image\", img) for img in os.listdir(os.path.join(save_path_test, \"image\"))]),\n",
    "        masks_path=sorted([os.path.join(save_path_test, \"mask\", mask) for mask in os.listdir(os.path.join(save_path_test, \"mask\"))])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b93916ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T05:47:30.771634Z",
     "iopub.status.busy": "2024-10-30T05:47:30.770844Z",
     "iopub.status.idle": "2024-10-30T05:47:30.775677Z",
     "shell.execute_reply": "2024-10-30T05:47:30.774840Z"
    },
    "papermill": {
     "duration": 0.139452,
     "end_time": "2024-10-30T05:47:30.777566",
     "exception": false,
     "start_time": "2024-10-30T05:47:30.638114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f08533d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T05:47:31.045274Z",
     "iopub.status.busy": "2024-10-30T05:47:31.044408Z",
     "iopub.status.idle": "2024-10-30T05:47:31.109854Z",
     "shell.execute_reply": "2024-10-30T05:47:31.108969Z"
    },
    "papermill": {
     "duration": 0.20149,
     "end_time": "2024-10-30T05:47:31.111890",
     "exception": false,
     "start_time": "2024-10-30T05:47:30.910400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e48b51b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T05:47:31.383498Z",
     "iopub.status.busy": "2024-10-30T05:47:31.382696Z",
     "iopub.status.idle": "2024-10-30T05:47:39.987958Z",
     "shell.execute_reply": "2024-10-30T05:47:39.987050Z"
    },
    "papermill": {
     "duration": 8.74522,
     "end_time": "2024-10-30T05:47:39.990556",
     "exception": false,
     "start_time": "2024-10-30T05:47:31.245336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
      "100%|██████████| 330M/330M [00:01<00:00, 201MB/s]\n",
      "/tmp/ipykernel_23/3754759716.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(pretrained_model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "build_unet_with_vit(\n",
       "  (e1): encoder_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (e2): encoder_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (e3): encoder_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (e4): encoder_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (channel_reduction): Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (vit_block): VisionTransformer(\n",
       "    (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (encoder): Encoder(\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (layers): Sequential(\n",
       "        (encoder_layer_0): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_1): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_2): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_3): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_4): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_5): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_6): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_7): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_8): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_9): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_10): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_11): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (heads): Sequential(\n",
       "      (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=1000, out_features=50176, bias=True)\n",
       "  (d1): decoder_block(\n",
       "    (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (d2): decoder_block(\n",
       "    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (d3): decoder_block(\n",
       "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (d4): decoder_block(\n",
       "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (outputs): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_path = \"/kaggle/input/model-5/model_saves/modality5wli.pth\"\n",
    "model = build_unet_with_vit().to(device)\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "814f1825",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T05:47:40.267024Z",
     "iopub.status.busy": "2024-10-30T05:47:40.266296Z",
     "iopub.status.idle": "2024-10-30T05:47:42.132204Z",
     "shell.execute_reply": "2024-10-30T05:47:42.131415Z"
    },
    "papermill": {
     "duration": 2.005483,
     "end_time": "2024-10-30T05:47:42.134576",
     "exception": false,
     "start_time": "2024-10-30T05:47:40.129093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_unet_with_vit().to(device)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = DiceBCELoss()\n",
    "loss_fn = DiceBCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55a435bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T05:47:42.405762Z",
     "iopub.status.busy": "2024-10-30T05:47:42.405358Z",
     "iopub.status.idle": "2024-10-30T05:47:42.410919Z",
     "shell.execute_reply": "2024-10-30T05:47:42.410053Z"
    },
    "papermill": {
     "duration": 0.143028,
     "end_time": "2024-10-30T05:47:42.412922",
     "exception": false,
     "start_time": "2024-10-30T05:47:42.269894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iou_score(preds, targets, smooth=1):\n",
    "    preds = (preds > 0.5).float()  # Apply a threshold to get binary predictions\n",
    "    targets = targets.float()\n",
    "    \n",
    "    intersection = (preds * targets).sum()\n",
    "    union = preds.sum() + targets.sum() - intersection\n",
    "    \n",
    "    return (intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45b43d00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T05:47:42.685091Z",
     "iopub.status.busy": "2024-10-30T05:47:42.684251Z",
     "iopub.status.idle": "2024-10-30T05:47:42.689211Z",
     "shell.execute_reply": "2024-10-30T05:47:42.688326Z"
    },
    "papermill": {
     "duration": 0.1435,
     "end_time": "2024-10-30T05:47:42.691119",
     "exception": false,
     "start_time": "2024-10-30T05:47:42.547619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time // 60)\n",
    "    elapsed_secs = int(elapsed_time % 60)\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "472bb1be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T05:47:42.971781Z",
     "iopub.status.busy": "2024-10-30T05:47:42.971033Z",
     "iopub.status.idle": "2024-10-30T11:24:22.070730Z",
     "shell.execute_reply": "2024-10-30T11:24:22.069587Z"
    },
    "papermill": {
     "duration": 20199.248083,
     "end_time": "2024-10-30T11:24:22.073081",
     "exception": false,
     "start_time": "2024-10-30T05:47:42.824998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:34<00:00,  5.77it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 43.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 16m 51s\n",
      "\tTrain Loss: 0.826\n",
      "\tVal. Loss: 0.937\n",
      "\tVal. IoU: 0.390 | Best IoU: 0.390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:32<00:00,  5.78it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 43.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 16m 49s\n",
      "\tTrain Loss: 0.522\n",
      "\tVal. Loss: 0.540\n",
      "\tVal. IoU: 0.565 | Best IoU: 0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:33<00:00,  5.78it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 43.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 16m 49s\n",
      "\tTrain Loss: 0.405\n",
      "\tVal. Loss: 0.422\n",
      "\tVal. IoU: 0.645 | Best IoU: 0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:34<00:00,  5.77it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 43.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 16m 50s\n",
      "\tTrain Loss: 0.348\n",
      "\tVal. Loss: 0.430\n",
      "\tVal. IoU: 0.639 | Best IoU: 0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:31<00:00,  5.79it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 43.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 16m 47s\n",
      "\tTrain Loss: 0.315\n",
      "\tVal. Loss: 0.362\n",
      "\tVal. IoU: 0.693 | Best IoU: 0.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:34<00:00,  5.77it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 43.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 16m 51s\n",
      "\tTrain Loss: 0.285\n",
      "\tVal. Loss: 0.447\n",
      "\tVal. IoU: 0.624 | Best IoU: 0.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:32<00:00,  5.78it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 43.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 16m 49s\n",
      "\tTrain Loss: 0.264\n",
      "\tVal. Loss: 0.368\n",
      "\tVal. IoU: 0.706 | Best IoU: 0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:34<00:00,  5.77it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 43.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 16m 51s\n",
      "\tTrain Loss: 0.255\n",
      "\tVal. Loss: 0.342\n",
      "\tVal. IoU: 0.704 | Best IoU: 0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:34<00:00,  5.77it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 42.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 16m 51s\n",
      "\tTrain Loss: 0.237\n",
      "\tVal. Loss: 0.350\n",
      "\tVal. IoU: 0.701 | Best IoU: 0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:33<00:00,  5.78it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 43.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 16m 50s\n",
      "\tTrain Loss: 0.222\n",
      "\tVal. Loss: 0.351\n",
      "\tVal. IoU: 0.703 | Best IoU: 0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:31<00:00,  5.79it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 44.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 16m 47s\n",
      "\tTrain Loss: 0.229\n",
      "\tVal. Loss: 0.324\n",
      "\tVal. IoU: 0.721 | Best IoU: 0.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:31<00:00,  5.79it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 43.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 16m 48s\n",
      "\tTrain Loss: 0.260\n",
      "\tVal. Loss: 0.411\n",
      "\tVal. IoU: 0.648 | Best IoU: 0.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:32<00:00,  5.79it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 43.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 16m 48s\n",
      "\tTrain Loss: 0.212\n",
      "\tVal. Loss: 0.309\n",
      "\tVal. IoU: 0.741 | Best IoU: 0.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:31<00:00,  5.79it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 43.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Time: 16m 48s\n",
      "\tTrain Loss: 0.276\n",
      "\tVal. Loss: 0.354\n",
      "\tVal. IoU: 0.691 | Best IoU: 0.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:32<00:00,  5.78it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 43.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 16m 49s\n",
      "\tTrain Loss: 0.207\n",
      "\tVal. Loss: 0.352\n",
      "\tVal. IoU: 0.700 | Best IoU: 0.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:32<00:00,  5.78it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 44.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 16m 48s\n",
      "\tTrain Loss: 0.191\n",
      "\tVal. Loss: 0.334\n",
      "\tVal. IoU: 0.717 | Best IoU: 0.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:33<00:00,  5.78it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 42.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Time: 16m 50s\n",
      "\tTrain Loss: 0.182\n",
      "\tVal. Loss: 0.270\n",
      "\tVal. IoU: 0.771 | Best IoU: 0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:35<00:00,  5.77it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 43.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Time: 16m 51s\n",
      "\tTrain Loss: 0.174\n",
      "\tVal. Loss: 0.286\n",
      "\tVal. IoU: 0.757 | Best IoU: 0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:35<00:00,  5.77it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 43.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Time: 16m 52s\n",
      "\tTrain Loss: 0.167\n",
      "\tVal. Loss: 0.276\n",
      "\tVal. IoU: 0.767 | Best IoU: 0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [16:35<00:00,  5.76it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:16<00:00, 43.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Time: 16m 52s\n",
      "\tTrain Loss: 0.159\n",
      "\tVal. Loss: 0.275\n",
      "\tVal. IoU: 0.769 | Best IoU: 0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train(model, loader, optimizer, loss_fn, device):\n",
    "    epoch_loss = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for x, y in tqdm(loader, desc='Training'):\n",
    "        x = x.to(device, dtype=torch.float32)\n",
    "        y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(loader)\n",
    "    return epoch_loss\n",
    "\n",
    "def evaluate(model, loader, loss_fn, device):\n",
    "    epoch_loss = 0.0\n",
    "    total_iou = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader, desc='Evaluating'):\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            total_iou += iou_score(y_pred, y)\n",
    "\n",
    "    epoch_loss /= len(loader)\n",
    "    average_iou = total_iou / len(loader)\n",
    "    return epoch_loss, average_iou\n",
    "\n",
    "# Training Loop\n",
    "# Initialize best IoU score\n",
    "best_iou = 0.0\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Training and validation\n",
    "    train_loss = train(model, train_loader, optimizer, loss_fn, device)\n",
    "    valid_loss, valid_iou = evaluate(model, test_loader, loss_fn, device)\n",
    "\n",
    "    # Update the best IoU if current IoU is higher\n",
    "    if valid_iou > best_iou:\n",
    "        best_iou = valid_iou\n",
    "\n",
    "    # Logging the epoch results\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\tVal. Loss: {valid_loss:.3f}')\n",
    "    print(f'\\tVal. IoU: {valid_iou:.3f} | Best IoU: {best_iou:.3f}')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5798061,
     "sourceId": 9522499,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5966522,
     "sourceId": 9746283,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20448.285758,
   "end_time": "2024-10-30T11:24:33.302644",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-30T05:43:45.016886",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
